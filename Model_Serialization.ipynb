{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Package"
      ],
      "metadata": {
        "id": "tRIKZYQ7vW3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skl2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "g4wzZBf7AwxH",
        "outputId": "b3fb4b9c-0cb4-4f20-b0dc-7a9d45a18d54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.17.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting onnx>=1.2.1 (from skl2onnx)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.5.2)\n",
            "Collecting onnxconverter-common>=1.7.0 (from skl2onnx)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (4.25.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (24.2)\n",
            "Collecting protobuf>=3.20.2 (from onnx>=1.2.1->skl2onnx)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.5.0)\n",
            "Downloading skl2onnx-1.17.0-py2.py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx, onnxconverter-common, skl2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 onnxconverter-common-1.14.0 protobuf-3.20.2 skl2onnx-1.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "26e83f32bd334c01b6d6fc86f4b14ddf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8smotfeDBXUB",
        "outputId": "a899150f-b08f-4acc-dc21-24c3e893931a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "dTVpR2rkvbQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "l_VIZJa2_shq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import skl2onnx\n",
        "import onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset Iris\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Membagi data menjadi training dan testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membuat dan melatih model RandomForest\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "print(f\"Akurasi model RandomForest: {accuracy_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edvvn0I__uLT",
        "outputId": "15fcd1a1-7180-4c55-e851-679b880e5a4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi model RandomForest: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pickle"
      ],
      "metadata": {
        "id": "FOgkpcnxvfFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model dengan Pickle\n",
        "start_time = time.time()\n",
        "with open('model_rf_pickle.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rf, f)\n",
        "pickle_time = time.time() - start_time\n",
        "\n",
        "# Memuat model dengan Pickle\n",
        "start_time = time.time()\n",
        "with open('model_rf_pickle.pkl', 'rb') as f:\n",
        "    model_rf_pickle = pickle.load(f)\n",
        "pickle_load_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "Ewx6KTqx_0TF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joblib"
      ],
      "metadata": {
        "id": "kMDE4P4Ovh7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model dengan Joblib\n",
        "start_time = time.time()\n",
        "joblib.dump(model_rf, 'model_rf_joblib.pkl')\n",
        "joblib_time = time.time() - start_time\n",
        "\n",
        "# Memuat model dengan Joblib\n",
        "start_time = time.time()\n",
        "model_rf_joblib = joblib.load('model_rf_joblib.pkl')\n",
        "joblib_load_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "p_iGqUaq_25H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX"
      ],
      "metadata": {
        "id": "b67HE_UovlZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi model RandomForest ke ONNX\n",
        "start_time = time.time()\n",
        "initial_types = [('input', skl2onnx.common.data_types.FloatTensorType([None, X_train.shape[1]]))]\n",
        "onnx_model = skl2onnx.convert_sklearn(model_rf, initial_types=initial_types)\n",
        "\n",
        "# Simpan model ONNX\n",
        "with open('model_rf.onnx', 'wb') as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "onnx_time = time.time() - start_time\n",
        "\n",
        "# Memuat model ONNX\n",
        "start_time = time.time()\n",
        "onnx_model_loaded = onnx.load('model_rf.onnx')\n",
        "onnx_load_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "DssFi4j8__Ks"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "S6BSq0LcvoPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model TensorFlow untuk eksperimen ini\n",
        "model_tf = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi dan latih model TensorFlow\n",
        "model_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_tf.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "\n",
        "# Menyimpan model TensorFlow\n",
        "start_time = time.time()\n",
        "model_tf.save('model_tf.h5')\n",
        "tf_time = time.time() - start_time\n",
        "\n",
        "# Memuat model TensorFlow\n",
        "start_time = time.time()\n",
        "model_tf_loaded = tf.keras.models.load_model('model_tf.h5')\n",
        "tf_load_time = time.time() - start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsjnJLWOAD80",
        "outputId": "7fddd44b-94d3-40b5-9008-65d8bbccd039"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Analysis"
      ],
      "metadata": {
        "id": "x4g3UCzjvrQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengukur ukuran file dari masing-masing metode serialisasi\n",
        "pickle_size = os.path.getsize('model_rf_pickle.pkl')\n",
        "joblib_size = os.path.getsize('model_rf_joblib.pkl')\n",
        "onnx_size = os.path.getsize('model_rf.onnx')\n",
        "tf_size = os.path.getsize('model_tf.h5')\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(f\"Pickle: Save time = {pickle_time:.4f}s, Load time = {pickle_load_time:.4f}s, File size = {pickle_size / 1024:.2f} KB\")\n",
        "print(f\"Joblib: Save time = {joblib_time:.4f}s, Load time = {joblib_load_time:.4f}s, File size = {joblib_size / 1024:.2f} KB\")\n",
        "print(f\"ONNX: Save time = {onnx_time:.4f}s, Load time = {onnx_load_time:.4f}s, File size = {onnx_size / 1024:.2f} KB\")\n",
        "print(f\"TensorFlow: Save time = {tf_time:.4f}s, Load time = {tf_load_time:.4f}s, File size = {tf_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFRgod06ASVh",
        "outputId": "6c5fa81d-d353-4f66-e60b-4da4cbb6e537"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle: Save time = 0.0288s, Load time = 0.0096s, File size = 309.79 KB\n",
            "Joblib: Save time = 0.0512s, Load time = 0.0300s, File size = 317.68 KB\n",
            "ONNX: Save time = 0.0904s, Load time = 0.0035s, File size = 128.18 KB\n",
            "TensorFlow: Save time = 0.0176s, Load time = 0.0345s, File size = 61.34 KB\n"
          ]
        }
      ]
    }
  ]
}